{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eNq4lCSSQWn"
   },
   "source": [
    "**Instituto Tecnológico de Costa Rica - TEC**\n",
    "\n",
    "***Inteligencia Artificial***\n",
    "\n",
    "*Docente: Kenneth Obando Rodríguez*\n",
    "\n",
    "---\n",
    "# Trabajo Corto 6: Red Neuronal\n",
    "---\n",
    "Estudiantes:\n",
    "- Rolando Mora Cordero\n",
    "- Esteban Guzmán\n",
    "\n",
    "Link del Cuaderno (recuerde configurar el acceso a público):\n",
    "- [Link de su respuesta](https://colab.research.google.com/drive/116PDV-WwkNgcNJaGoLzrAq2Roblf1m25?usp=sharing)\n",
    "\n",
    "    **Nota:** Este trabajo tiene como objetivo promover la comprensión de la materia y su importancia en la elección de algoritmos. Los alumnos deben evitar copiar y pegar directamente información de fuentes externas, y en su lugar, demostrar su propio análisis y comprensión.\n",
    "\n",
    "## Entrega\n",
    "Debe entregar un archivo comprimido por el TecDigital, incluyendo un documento pdf con los resultados de los experimentos y pruebas. Fecha de Entrega domingo 10 de noviembre, 2024, a las 22:00 hrs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onCmI27E3Jit"
   },
   "source": [
    "## Actividad: Creación y Entrenamiento de una Red Neuronal desde Cero\n",
    "Objetivo:\n",
    "\n",
    "1. Comprender los fundamentos de las redes neuronales.\n",
    "2. Implementar una red neuronal simple sin usar frameworks.\n",
    "3. Entrenar la red neuronal para resolver un problema de clasificación.\n",
    "\n",
    "### Descripción:\n",
    "\n",
    "En esta actividad, los estudiantes implementarán una red neuronal simple con una capa oculta para clasificar datos. Se utilizará el lenguaje de programación Python y se evitarán frameworks de aprendizaje automático. La actividad se dividirá en los siguientes pasos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Implementación de las funciones básicas\n",
    "\n",
    "Función de activación: Implementar la función sigmoide como función de activación. En este caso implementa la función sigmoid\n",
    "\n",
    "**Fórmula:**  σ(x) = 1 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lR0PIY3USEAu"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiS1Gzl2ShRm"
   },
   "source": [
    "2. **Derivada de la función de activación:** Implementar la derivada de la función sigmoide.\n",
    "\n",
    "**Fórmula:** σ'(x) = σ(x) * (1 - σ(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D59kb0dLS4RY"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "  return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLUnk4o4SjTg"
   },
   "source": [
    "**Paso 2: Inicialización de la red neuronal**\n",
    "\n",
    "1. **Inicializar los pesos:**  Crear matrices de pesos aleatorios para las conexiones entre las capas de entrada, oculta y salida.\n",
    "2. **Definir la arquitectura:** Establecer el número de neuronas en cada capa (entrada, oculta y salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cO-pwwHqS1uG"
   },
   "outputs": [],
   "source": [
    "# Inicializar pesos con valores aleatorios entre -1 y 1\n",
    "def initialize_network(input_size, hidden_size, output_size):\n",
    "  # matriz de tamaño (input_size, hidden_size) que contiene los pesos para las conexiones entre la capa de entrada y la capa oculta.\n",
    "  input_hidden_weights = np.random.uniform(-1, 1, (input_size, hidden_size))\n",
    "  #  matriz de tamaño (hidden_size, output_size) que contiene los pesos para las conexiones entre la capa oculta y la capa de salida.\n",
    "  hidden_output_weights = np.random.uniform(-1, 1, (hidden_size, output_size))\n",
    "\n",
    "  return input_hidden_weights, hidden_output_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWTgU5bVSoag"
   },
   "source": [
    "**Paso 3: Propagación hacia adelante (Forward propagation)**\n",
    "\n",
    "1. **Calcular la salida de la capa oculta:** Multiplicar las entradas por los pesos de la capa de entrada a la oculta y aplicar la función de activación.\n",
    "\n",
    "**Fórmula:** hidden_output = σ(input * input_hidden_weights)\n",
    "\n",
    "2. **Calcular la salida de la capa de salida:** Multiplicar la salida de la capa oculta por los pesos de la capa oculta a la salida y aplicar la función de activación.\n",
    "\n",
    "   **Fórmula:** output = σ(hidden_output * hidden_output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xxbf-SifS5sB"
   },
   "outputs": [],
   "source": [
    "def forward_propagation(inputs, input_hidden_weights, hidden_output_weights):\n",
    "    # Calcula las entradas para la capa oculta multiplicando las entradas por los pesos de la capa de entrada a la capa oculta\n",
    "    hidden_layer_input = np.dot(inputs, input_hidden_weights)\n",
    "    \n",
    "    # Aplica la función de activación sigmoide a las entradas de la capa oculta para obtener las salidas de esta capa\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    # Calcula las entradas para la capa de salida multiplicando las salidas de la capa oculta por los pesos de la capa oculta a la capa de salida\n",
    "    output_layer_input = np.dot(hidden_layer_output, hidden_output_weights)\n",
    "    \n",
    "    # Aplica la función de activación sigmoide a las entradas de la capa de salida para obtener las salidas finales de la red\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Devuelve las salidas de la capa oculta y de la capa de salida (salida final de la red)\n",
    "    return hidden_layer_output, output_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88Q2H8vvSpgk"
   },
   "source": [
    "**Paso 4: Propagación hacia atrás (Backpropagation)**\n",
    "\n",
    "1. **Calcular el error de la capa de salida:** Restar la salida deseada de la salida real.\n",
    "2. **Calcular el error de la capa oculta:** Propagar el error de la capa de salida hacia atrás a través de los pesos y la derivada de la función de activación.\n",
    "3. **Actualizar los pesos:** Ajustar los pesos de la red neuronal en función del error calculado.\n",
    "\n",
    "   **Fórmula:**\n",
    "      * hidden_output_weights += learning_rate * output_error * σ'(output) * hidden_output\n",
    "      * input_hidden_weights += learning_rate * hidden_error * σ'(hidden_output) * input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NjoZNN5wS7T6"
   },
   "outputs": [],
   "source": [
    "def backpropagation(inputs, hidden_layer_output, output_layer_output, desired_output, input_hidden_weights, hidden_output_weights, learning_rate):\n",
    "    # Calcular el error de la capa de salida como la diferencia entre la salida deseada y la salida de la red\n",
    "    output_error = desired_output - output_layer_output\n",
    "    \n",
    "    # Calcular el delta de la capa de salida (gradiente) multiplicando el error por la derivada de la función sigmoide aplicada a la salida de la red\n",
    "    output_delta = output_error * sigmoid_derivative(output_layer_output)\n",
    "\n",
    "    # Calcular el error de la capa oculta propagando el delta de salida hacia atrás a través de los pesos de la capa oculta a la capa de salida\n",
    "    hidden_error = np.dot(output_delta, hidden_output_weights.T)\n",
    "    \n",
    "    # Calcular el delta de la capa oculta multiplicando el error de la capa oculta por la derivada de la función sigmoide aplicada a la salida de la capa oculta\n",
    "    hidden_delta = hidden_error * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Asegurarse de que las dimensiones de las salidas y deltas de la capa oculta sean correctas para la multiplicación (transformarlas en vectores columna)\n",
    "    hidden_layer_output = hidden_layer_output.reshape(-1, 1)\n",
    "    output_delta = output_delta.reshape(-1, 1)\n",
    "\n",
    "    # Actualizar los pesos de la capa oculta a la capa de salida utilizando la tasa de aprendizaje y el producto de la salida de la capa oculta con el delta de salida\n",
    "    hidden_output_weights += learning_rate * np.dot(hidden_layer_output, output_delta.T)\n",
    "\n",
    "    # Asegurarse de que las dimensiones de las entradas y deltas de la capa oculta sean correctas para la multiplicación (transformarlas en vectores columna)\n",
    "    inputs = inputs.reshape(-1, 1)\n",
    "    hidden_delta = hidden_delta.reshape(-1, 1)\n",
    "\n",
    "    # Actualizar los pesos de la capa de entrada a la capa oculta utilizando la tasa de aprendizaje y el producto de las entradas con el delta de la capa oculta\n",
    "    input_hidden_weights += learning_rate * np.dot(inputs, hidden_delta.T)\n",
    "\n",
    "    # Retornar los pesos actualizados de ambas capas\n",
    "    return input_hidden_weights, hidden_output_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsEvfDnzSt_j"
   },
   "source": [
    "**Paso 5: Preparación del conjunto de datos de ejemplo**\n",
    "\n",
    "1. **Crear un conjunto de datos:**  Define un conjunto de datos de ejemplo para entrenar la red neuronal. Puedes usar un problema simple como la compuerta XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LXITmxp6UGop"
   },
   "outputs": [],
   "source": [
    "# Datos de entrada para la compuerta XOR\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "# Salidas deseadas para la compuerta XOR\n",
    "desired_outputs = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG8DBCHhT8hQ"
   },
   "source": [
    "**Paso 6: Entrenamiento de la red neuronal**\n",
    "\n",
    "1. **Inicializar la red:** Define la arquitectura de la red (número de neuronas en cada capa) e inicializa los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YGZmN4nwUISZ"
   },
   "outputs": [],
   "source": [
    "# Inicializar la red\n",
    "input_size = 2  # Dos entradas para la compuerta XOR\n",
    "hidden_size = 3  # Tres neuronas en la capa oculta\n",
    "output_size = 1  # Una salida para la compuerta XOR\n",
    "learning_rate = 0.5  # Tasa de aprendizaje\n",
    "epochs = 10000  # Número de épocas de entrenamiento\n",
    "\n",
    "input_hidden_weights, hidden_output_weights = initialize_network(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54_Y1rinT9_A"
   },
   "source": [
    "2. **Iterar sobre el conjunto de datos de entrenamiento:** Presentar cada ejemplo de entrenamiento a la red neuronal y realizar la propagación hacia adelante y hacia atrás para ajustar los pesos. Repetir este proceso durante un número determinado de épocas. Reporta el error en cada epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrcpXVz3Tunb",
    "outputId": "05808101-d1f9-405a-ed1b-301630963920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000, Error: 0.27461486832538934\n",
      "Epoch 1000/10000, Error: 0.25323007939310815\n",
      "Epoch 2000/10000, Error: 0.2504255228276692\n",
      "Epoch 3000/10000, Error: 0.23699508752717988\n",
      "Epoch 4000/10000, Error: 0.22378766747528553\n",
      "Epoch 5000/10000, Error: 0.2145654938647764\n",
      "Epoch 6000/10000, Error: 0.20624924069821549\n",
      "Epoch 7000/10000, Error: 0.20112660386013323\n",
      "Epoch 8000/10000, Error: 0.19833965111194432\n",
      "Epoch 9000/10000, Error: 0.19650790385728217\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre el conjunto de datos de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0  # Inicializar el error total de cada época\n",
    "\n",
    "    # Iterar sobre cada ejemplo de entrada en el conjunto de datos\n",
    "    for i in range(len(inputs)):\n",
    "        input_example = inputs[i]  # Obtener el ejemplo de entrada actual\n",
    "        desired_output_example = desired_outputs[i]  # Obtener la salida deseada para el ejemplo actual\n",
    "\n",
    "        # Paso de propagación hacia adelante para obtener las salidas de la capa oculta y la capa de salida\n",
    "        hidden_layer_output, output_layer_output = forward_propagation(input_example, input_hidden_weights, hidden_output_weights)\n",
    "\n",
    "        # Realizar retropropagación para ajustar los pesos de la red\n",
    "        input_hidden_weights, hidden_output_weights = backpropagation(\n",
    "            input_example, hidden_layer_output, output_layer_output, \n",
    "            desired_output_example, input_hidden_weights, hidden_output_weights, learning_rate\n",
    "        )\n",
    "\n",
    "        # Calcular el error cuadrático medio para este ejemplo de entrenamiento\n",
    "        error = np.mean((desired_output_example - output_layer_output) ** 2)\n",
    "        total_error += error  # Acumular el error para obtener el total de la época\n",
    "\n",
    "    # Cada 1000 épocas, imprimir el error promedio de la época actual\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Error: {total_error / len(inputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehKmrudfUA7E"
   },
   "source": [
    "**Paso 7: Evaluación de la red neuronal**\n",
    "\n",
    "1. **Presentar nuevos datos a la red:**  Utiliza un conjunto de datos de prueba para evaluar el rendimiento de la red neuronal entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnwgOZp5UoYl",
    "outputId": "d79b29dd-8f83-4963-e71b-bc54035fae01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salidas de la red para los datos de prueba:\n",
      "[[0.10470527]\n",
      " [0.49423583]\n",
      " [0.49395277]\n",
      " [0.5020758 ]]\n",
      "\n",
      "Salidas deseadas:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Presentar nuevos datos a la red (usando los mismos datos de entrenamiento como ejemplo)\n",
    "hidden_layer_output, test_outputs = forward_propagation(inputs, input_hidden_weights, hidden_output_weights)\n",
    "\n",
    "# Imprimir las salidas de la red para los datos de prueba\n",
    "print(\"Salidas de la red para los datos de prueba:\")\n",
    "print(test_outputs)\n",
    "\n",
    "# Comparar las salidas de la red con las salidas deseadas\n",
    "print(\"\\nSalidas deseadas:\")\n",
    "print(desired_outputs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
